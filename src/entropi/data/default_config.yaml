# Entropi Configuration
# This file is copied to ~/.entropi/config.yaml during installation
# and to .entropi/config.yaml on first run in each project

models:
  thinking:
    path: ~/models/gguf/Qwen_Qwen3-14B-Q4_K_M.gguf
    adapter: qwen3
    context_length: 8192
    gpu_layers: -1
  normal:
    path: ~/models/gguf/Qwen_Qwen3-8B-Q4_K_M.gguf
    adapter: qwen3
    context_length: 8192
    gpu_layers: -1
  code:
    path: ~/models/gguf/Qwen2.5-Coder-7B-Instruct-Q4_K_M.gguf
    adapter: qwen2
    context_length: 8192
    gpu_layers: -1
  simple:
    # Simple responses - uses same model as normal (can specialize later)
    path: ~/models/gguf/Qwen_Qwen3-8B-Q4_K_M.gguf
    adapter: qwen3
    context_length: 8192
    gpu_layers: -1
  router:
    # Classification only - small model for task routing
    path: ~/models/gguf/qwen2.5-0.5b-instruct-q8_0.gguf
    adapter: qwen2
    context_length: 4096
    gpu_layers: -1
  default: normal

thinking:
  enabled: false

routing:
  enabled: true
  fallback_model: normal

log_level: INFO
